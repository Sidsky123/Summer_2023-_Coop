{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8fa215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame: (606, 14)\n",
      "age          61.0\n",
      "sex           1.0\n",
      "cp            0.0\n",
      "trestbps    148.0\n",
      "chol        203.0\n",
      "fbs           0.0\n",
      "restecg       1.0\n",
      "thalach     161.0\n",
      "exang         0.0\n",
      "oldpeak       0.0\n",
      "slope         2.0\n",
      "ca            1.0\n",
      "thal          3.0\n",
      "target        0.0\n",
      "Name: 1, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Loss: 0.6907\n",
      "epsilon list is  [5.678019591392215]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Avg. Loss: 0.6891\n",
      "epsilon list is  [5.678019591392215, 6.467638063596675]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Avg. Loss: 0.6862\n",
      "epsilon list is  [5.678019591392215, 6.467638063596675, 7.080857977608617]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Avg. Loss: 0.6863\n",
      "epsilon list is  [5.678019591392215, 6.467638063596675, 7.080857977608617, 7.605856024671113]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Avg. Loss: 0.6816\n",
      "epsilon list is  [5.678019591392215, 6.467638063596675, 7.080857977608617, 7.605856024671113, 8.075898053002357]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Avg. Loss: 0.6759\n",
      "epsilon list is  [5.678019591392215, 6.467638063596675, 7.080857977608617, 7.605856024671113, 8.075898053002357, 8.507502864593228]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Avg. Loss: 0.6697\n",
      "epsilon list is  [5.678019591392215, 6.467638063596675, 7.080857977608617, 7.605856024671113, 8.075898053002357, 8.507502864593228, 8.910233248221472]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Avg. Loss: 0.6645\n",
      "epsilon list is  [5.678019591392215, 6.467638063596675, 7.080857977608617, 7.605856024671113, 8.075898053002357, 8.507502864593228, 8.910233248221472, 9.29022600775257]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Avg. Loss: 0.6477\n",
      "epsilon list is  [5.678019591392215, 6.467638063596675, 7.080857977608617, 7.605856024671113, 8.075898053002357, 8.507502864593228, 8.910233248221472, 9.29022600775257, 9.651678385165262]\n",
      "Test Accuracy: 0.6311\n",
      "Confusion Matrix:\n",
      "[[ 6 45]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.12      0.21        51\n",
      "         1.0       0.61      1.00      0.76        71\n",
      "\n",
      "    accuracy                           0.63       122\n",
      "   macro avg       0.81      0.56      0.48       122\n",
      "weighted avg       0.77      0.63      0.53       122\n",
      "\n",
      "Test Accuracy: 0.6311\n",
      "Confusion Matrix:\n",
      "[[ 6 45]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.12      0.21        51\n",
      "         1.0       0.61      1.00      0.76        71\n",
      "\n",
      "    accuracy                           0.63       122\n",
      "   macro avg       0.81      0.56      0.48       122\n",
      "weighted avg       0.77      0.63      0.53       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6311475409836066]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Loss: 0.6895\n",
      "epsilon list is  [4.1502136976115525]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Avg. Loss: 0.6832\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Avg. Loss: 0.6812\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Avg. Loss: 0.6756\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726]\n",
      "Test Accuracy: 0.5902\n",
      "Confusion Matrix:\n",
      "[[ 1 50]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04        51\n",
      "         1.0       0.59      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.59       122\n",
      "   macro avg       0.79      0.51      0.39       122\n",
      "weighted avg       0.76      0.59      0.45       122\n",
      "\n",
      "Test Accuracy: 0.5902\n",
      "Confusion Matrix:\n",
      "[[ 1 50]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04        51\n",
      "         1.0       0.59      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.59       122\n",
      "   macro avg       0.79      0.51      0.39       122\n",
      "weighted avg       0.76      0.59      0.45       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Avg. Loss: 0.6684\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134]\n",
      "Test Accuracy: 0.6230\n",
      "Confusion Matrix:\n",
      "[[ 5 46]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.10      0.18        51\n",
      "         1.0       0.61      1.00      0.76        71\n",
      "\n",
      "    accuracy                           0.62       122\n",
      "   macro avg       0.80      0.55      0.47       122\n",
      "weighted avg       0.77      0.62      0.51       122\n",
      "\n",
      "Test Accuracy: 0.6230\n",
      "Confusion Matrix:\n",
      "[[ 5 46]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.10      0.18        51\n",
      "         1.0       0.61      1.00      0.76        71\n",
      "\n",
      "    accuracy                           0.62       122\n",
      "   macro avg       0.80      0.55      0.47       122\n",
      "weighted avg       0.77      0.62      0.51       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Avg. Loss: 0.6579\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677]\n",
      "Test Accuracy: 0.7295\n",
      "Confusion Matrix:\n",
      "[[18 33]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.35      0.52        51\n",
      "         1.0       0.68      1.00      0.81        71\n",
      "\n",
      "    accuracy                           0.73       122\n",
      "   macro avg       0.84      0.68      0.67       122\n",
      "weighted avg       0.82      0.73      0.69       122\n",
      "\n",
      "Test Accuracy: 0.7295\n",
      "Confusion Matrix:\n",
      "[[18 33]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.35      0.52        51\n",
      "         1.0       0.68      1.00      0.81        71\n",
      "\n",
      "    accuracy                           0.73       122\n",
      "   macro avg       0.84      0.68      0.67       122\n",
      "weighted avg       0.82      0.73      0.69       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Avg. Loss: 0.6368\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777]\n",
      "Test Accuracy: 0.8033\n",
      "Confusion Matrix:\n",
      "[[30 21]\n",
      " [ 3 68]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.59      0.71        51\n",
      "         1.0       0.76      0.96      0.85        71\n",
      "\n",
      "    accuracy                           0.80       122\n",
      "   macro avg       0.84      0.77      0.78       122\n",
      "weighted avg       0.82      0.80      0.79       122\n",
      "\n",
      "Test Accuracy: 0.8033\n",
      "Confusion Matrix:\n",
      "[[30 21]\n",
      " [ 3 68]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.59      0.71        51\n",
      "         1.0       0.76      0.96      0.85        71\n",
      "\n",
      "    accuracy                           0.80       122\n",
      "   macro avg       0.84      0.77      0.78       122\n",
      "weighted avg       0.82      0.80      0.79       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Avg. Loss: 0.6117\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[38 13]\n",
      " [ 5 66]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.75      0.81        51\n",
      "         1.0       0.84      0.93      0.88        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.86      0.84      0.84       122\n",
      "weighted avg       0.86      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[38 13]\n",
      " [ 5 66]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.75      0.81        51\n",
      "         1.0       0.84      0.93      0.88        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.86      0.84      0.84       122\n",
      "weighted avg       0.86      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Avg. Loss: 0.5835\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887]\n",
      "Test Accuracy: 0.8361\n",
      "Confusion Matrix:\n",
      "[[40 11]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.78      0.80        51\n",
      "         1.0       0.85      0.87      0.86        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.83      0.83      0.83       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8361\n",
      "Confusion Matrix:\n",
      "[[40 11]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.78      0.80        51\n",
      "         1.0       0.85      0.87      0.86        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.83      0.83      0.83       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Avg. Loss: 0.5421\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928]\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.82      0.82        51\n",
      "         1.0       0.87      0.86      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.82      0.82        51\n",
      "         1.0       0.87      0.86      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Avg. Loss: 0.5261\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846]\n",
      "Test Accuracy: 0.8361\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [12 59]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.84      0.81        51\n",
      "         1.0       0.88      0.83      0.86        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.83      0.84      0.83       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8361\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [12 59]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.84      0.81        51\n",
      "         1.0       0.88      0.83      0.86        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.83      0.84      0.83       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Avg. Loss: 0.4779\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263]\n",
      "Test Accuracy: 0.8361\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [12 59]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.84      0.81        51\n",
      "         1.0       0.88      0.83      0.86        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.83      0.84      0.83       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8361\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [12 59]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.84      0.81        51\n",
      "         1.0       0.88      0.83      0.86        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.83      0.84      0.83       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Avg. Loss: 0.4461\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048]\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [11 60]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.84      0.82        51\n",
      "         1.0       0.88      0.85      0.86        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.85      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [11 60]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.84      0.82        51\n",
      "         1.0       0.88      0.85      0.86        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.85      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918, 0.8442622950819673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Avg. Loss: 0.4282\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887]\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [11 60]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.84      0.82        51\n",
      "         1.0       0.88      0.85      0.86        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.85      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [11 60]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.84      0.82        51\n",
      "         1.0       0.88      0.85      0.86        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.85      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918, 0.8442622950819673, 0.8442622950819673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Avg. Loss: 0.3938\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287]\n",
      "Test Accuracy: 0.8689\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.84      0.84        51\n",
      "         1.0       0.89      0.89      0.89        71\n",
      "\n",
      "    accuracy                           0.87       122\n",
      "   macro avg       0.87      0.87      0.87       122\n",
      "weighted avg       0.87      0.87      0.87       122\n",
      "\n",
      "Test Accuracy: 0.8689\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.84      0.84        51\n",
      "         1.0       0.89      0.89      0.89        71\n",
      "\n",
      "    accuracy                           0.87       122\n",
      "   macro avg       0.87      0.87      0.87       122\n",
      "weighted avg       0.87      0.87      0.87       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918, 0.8442622950819673, 0.8442622950819673, 0.8688524590163934]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Avg. Loss: 0.4065\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.84      0.83        51\n",
      "         1.0       0.88      0.86      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.84      0.83        51\n",
      "         1.0       0.88      0.86      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918, 0.8442622950819673, 0.8442622950819673, 0.8688524590163934, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Avg. Loss: 0.3985\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.84      0.83        51\n",
      "         1.0       0.89      0.87      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.84      0.83        51\n",
      "         1.0       0.89      0.87      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918, 0.8442622950819673, 0.8442622950819673, 0.8688524590163934, 0.8524590163934426, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Avg. Loss: 0.4048\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.80      0.82        51\n",
      "         1.0       0.86      0.89      0.88        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.80      0.82        51\n",
      "         1.0       0.86      0.89      0.88        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918, 0.8442622950819673, 0.8442622950819673, 0.8688524590163934, 0.8524590163934426, 0.860655737704918, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Avg. Loss: 0.4093\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918, 0.8442622950819673, 0.8442622950819673, 0.8688524590163934, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Avg. Loss: 0.4071\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918, 0.8442622950819673, 0.8442622950819673, 0.8688524590163934, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.860655737704918, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Avg. Loss: 0.4310\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272, 9.299034730630312]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918, 0.8442622950819673, 0.8442622950819673, 0.8688524590163934, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Avg. Loss: 0.4614\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272, 9.299034730630312, 9.47798056108359]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918, 0.8442622950819673, 0.8442622950819673, 0.8688524590163934, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Avg. Loss: 0.4635\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272, 9.299034730630312, 9.47798056108359, 9.654073569144057]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918, 0.8442622950819673, 0.8442622950819673, 0.8688524590163934, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Avg. Loss: 0.4323\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272, 9.299034730630312, 9.47798056108359, 9.654073569144057, 9.82748481670542]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5901639344262295, 0.6229508196721312, 0.7295081967213115, 0.8032786885245902, 0.8524590163934426, 0.8360655737704918, 0.8442622950819673, 0.8360655737704918, 0.8360655737704918, 0.8442622950819673, 0.8442622950819673, 0.8688524590163934, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Loss: 0.6896\n",
      "epsilon list is  [3.0192557293821984]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Avg. Loss: 0.6859\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Avg. Loss: 0.6823\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Avg. Loss: 0.6816\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Avg. Loss: 0.6756\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Avg. Loss: 0.6723\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Avg. Loss: 0.6643\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004]\n",
      "Test Accuracy: 0.6066\n",
      "Confusion Matrix:\n",
      "[[ 3 48]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.06      0.11        51\n",
      "         1.0       0.60      1.00      0.75        71\n",
      "\n",
      "    accuracy                           0.61       122\n",
      "   macro avg       0.80      0.53      0.43       122\n",
      "weighted avg       0.77      0.61      0.48       122\n",
      "\n",
      "Test Accuracy: 0.6066\n",
      "Confusion Matrix:\n",
      "[[ 3 48]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.06      0.11        51\n",
      "         1.0       0.60      1.00      0.75        71\n",
      "\n",
      "    accuracy                           0.61       122\n",
      "   macro avg       0.80      0.53      0.43       122\n",
      "weighted avg       0.77      0.61      0.48       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Avg. Loss: 0.6548\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467]\n",
      "Test Accuracy: 0.7049\n",
      "Confusion Matrix:\n",
      "[[15 36]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.29      0.45        51\n",
      "         1.0       0.66      1.00      0.80        71\n",
      "\n",
      "    accuracy                           0.70       122\n",
      "   macro avg       0.83      0.65      0.63       122\n",
      "weighted avg       0.80      0.70      0.65       122\n",
      "\n",
      "Test Accuracy: 0.7049\n",
      "Confusion Matrix:\n",
      "[[15 36]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.29      0.45        51\n",
      "         1.0       0.66      1.00      0.80        71\n",
      "\n",
      "    accuracy                           0.70       122\n",
      "   macro avg       0.83      0.65      0.63       122\n",
      "weighted avg       0.80      0.70      0.65       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Avg. Loss: 0.6405\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066]\n",
      "Test Accuracy: 0.7459\n",
      "Confusion Matrix:\n",
      "[[20 31]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.39      0.56        51\n",
      "         1.0       0.70      1.00      0.82        71\n",
      "\n",
      "    accuracy                           0.75       122\n",
      "   macro avg       0.85      0.70      0.69       122\n",
      "weighted avg       0.82      0.75      0.71       122\n",
      "\n",
      "Test Accuracy: 0.7459\n",
      "Confusion Matrix:\n",
      "[[20 31]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.39      0.56        51\n",
      "         1.0       0.70      1.00      0.82        71\n",
      "\n",
      "    accuracy                           0.75       122\n",
      "   macro avg       0.85      0.70      0.69       122\n",
      "weighted avg       0.82      0.75      0.71       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Avg. Loss: 0.6130\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685]\n",
      "Test Accuracy: 0.8115\n",
      "Confusion Matrix:\n",
      "[[28 23]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.55      0.71        51\n",
      "         1.0       0.76      1.00      0.86        71\n",
      "\n",
      "    accuracy                           0.81       122\n",
      "   macro avg       0.88      0.77      0.78       122\n",
      "weighted avg       0.86      0.81      0.80       122\n",
      "\n",
      "Test Accuracy: 0.8115\n",
      "Confusion Matrix:\n",
      "[[28 23]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.55      0.71        51\n",
      "         1.0       0.76      1.00      0.86        71\n",
      "\n",
      "    accuracy                           0.81       122\n",
      "   macro avg       0.88      0.77      0.78       122\n",
      "weighted avg       0.86      0.81      0.80       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Avg. Loss: 0.5845\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[37 14]\n",
      " [ 4 67]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.73      0.80        51\n",
      "         1.0       0.83      0.94      0.88        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.86      0.83      0.84       122\n",
      "weighted avg       0.86      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[37 14]\n",
      " [ 4 67]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.73      0.80        51\n",
      "         1.0       0.83      0.94      0.88        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.86      0.83      0.84       122\n",
      "weighted avg       0.86      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Avg. Loss: 0.5562\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[40 11]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.78      0.82        51\n",
      "         1.0       0.85      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.84      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[40 11]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.78      0.82        51\n",
      "         1.0       0.85      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.84      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Avg. Loss: 0.5098\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767]\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[39 12]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.76      0.80        51\n",
      "         1.0       0.84      0.90      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.83      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[39 12]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.76      0.80        51\n",
      "         1.0       0.84      0.90      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.83      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Avg. Loss: 0.4819\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[40 11]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.78      0.82        51\n",
      "         1.0       0.85      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.84      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[40 11]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.78      0.82        51\n",
      "         1.0       0.85      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.84      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Avg. Loss: 0.4541\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Avg. Loss: 0.4258\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Avg. Loss: 0.4098\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921]\n",
      "Test Accuracy: 0.8852\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.86      0.86        51\n",
      "         1.0       0.90      0.90      0.90        71\n",
      "\n",
      "    accuracy                           0.89       122\n",
      "   macro avg       0.88      0.88      0.88       122\n",
      "weighted avg       0.89      0.89      0.89       122\n",
      "\n",
      "Test Accuracy: 0.8852\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.86      0.86        51\n",
      "         1.0       0.90      0.90      0.90        71\n",
      "\n",
      "    accuracy                           0.89       122\n",
      "   macro avg       0.88      0.88      0.88       122\n",
      "weighted avg       0.89      0.89      0.89       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Avg. Loss: 0.4043\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158]\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.86      0.85        51\n",
      "         1.0       0.90      0.89      0.89        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.88      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.86      0.85        51\n",
      "         1.0       0.90      0.89      0.89        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.88      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Avg. Loss: 0.3925\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958]\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.86      0.85        51\n",
      "         1.0       0.90      0.89      0.89        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.88      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.86      0.85        51\n",
      "         1.0       0.90      0.89      0.89        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.88      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Avg. Loss: 0.3790\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849]\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.86      0.85        51\n",
      "         1.0       0.90      0.89      0.89        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.88      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.86      0.85        51\n",
      "         1.0       0.90      0.89      0.89        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.88      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Avg. Loss: 0.4246\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.82      0.83        51\n",
      "         1.0       0.88      0.89      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.82      0.83        51\n",
      "         1.0       0.88      0.89      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Avg. Loss: 0.4213\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281]\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.86      0.85        51\n",
      "         1.0       0.90      0.89      0.89        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.88      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.86      0.85        51\n",
      "         1.0       0.90      0.89      0.89        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.88      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Avg. Loss: 0.4183\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613]\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.86      0.85        51\n",
      "         1.0       0.90      0.89      0.89        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.88      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.86      0.85        51\n",
      "         1.0       0.90      0.89      0.89        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.88      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Avg. Loss: 0.4544\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Avg. Loss: 0.4341\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.82      0.83        51\n",
      "         1.0       0.88      0.89      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 8 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.82      0.83        51\n",
      "         1.0       0.88      0.89      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Avg. Loss: 0.4229\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Avg. Loss: 0.4334\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Avg. Loss: 0.3873\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.86      0.84        51\n",
      "         1.0       0.90      0.86      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.86      0.84        51\n",
      "         1.0       0.90      0.86      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Avg. Loss: 0.4168\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.86      0.84        51\n",
      "         1.0       0.90      0.86      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.86      0.84        51\n",
      "         1.0       0.90      0.86      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Avg. Loss: 0.4786\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.86      0.84        51\n",
      "         1.0       0.90      0.86      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.86      0.84        51\n",
      "         1.0       0.90      0.86      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Avg. Loss: 0.4327\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015]\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.82      0.82        51\n",
      "         1.0       0.87      0.86      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.82      0.82        51\n",
      "         1.0       0.87      0.86      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Avg. Loss: 0.4328\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.86      0.84        51\n",
      "         1.0       0.90      0.86      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.86      0.84        51\n",
      "         1.0       0.90      0.86      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Avg. Loss: 0.4534\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [11 60]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.86      0.83        51\n",
      "         1.0       0.90      0.85      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.86      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [11 60]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.86      0.83        51\n",
      "         1.0       0.90      0.85      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.86      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Avg. Loss: 0.4871\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Avg. Loss: 0.4915\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568]\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.82      0.82        51\n",
      "         1.0       0.87      0.86      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.82      0.82        51\n",
      "         1.0       0.87      0.86      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Avg. Loss: 0.4533\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731]\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.82      0.82        51\n",
      "         1.0       0.87      0.86      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.82      0.82        51\n",
      "         1.0       0.87      0.86      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Avg. Loss: 0.4831\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Avg. Loss: 0.4498\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445, 8.755825779999494]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.86      0.84        51\n",
      "         1.0       0.90      0.86      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.86      0.84        51\n",
      "         1.0       0.90      0.86      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.86      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Avg. Loss: 0.4498\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445, 8.755825779999494, 8.86405339521516]\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.82      0.82        51\n",
      "         1.0       0.87      0.86      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [10 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.82      0.82        51\n",
      "         1.0       0.87      0.86      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.8442622950819673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Avg. Loss: 0.4757\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445, 8.755825779999494, 8.86405339521516, 8.971302146743026]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.8442622950819673, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Avg. Loss: 0.5140\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445, 8.755825779999494, 8.86405339521516, 8.971302146743026, 9.077608267949133]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.8442622950819673, 0.8524590163934426, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Avg. Loss: 0.4873\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445, 8.755825779999494, 8.86405339521516, 8.971302146743026, 9.077608267949133, 9.183000923287103]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.8442622950819673, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Avg. Loss: 0.5013\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445, 8.755825779999494, 8.86405339521516, 8.971302146743026, 9.077608267949133, 9.183000923287103, 9.287507700817283]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.8442622950819673, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Avg. Loss: 0.5384\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445, 8.755825779999494, 8.86405339521516, 8.971302146743026, 9.077608267949133, 9.183000923287103, 9.287507700817283, 9.391159644779835]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        51\n",
      "         1.0       0.87      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.85      0.85      0.85       122\n",
      "weighted avg       0.85      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.8442622950819673, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Avg. Loss: 0.4601\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445, 8.755825779999494, 8.86405339521516, 8.971302146743026, 9.077608267949133, 9.183000923287103, 9.287507700817283, 9.391159644779835, 9.493978276292367]\n",
      "Test Accuracy: 0.8689\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.85        51\n",
      "         1.0       0.90      0.87      0.89        71\n",
      "\n",
      "    accuracy                           0.87       122\n",
      "   macro avg       0.86      0.87      0.87       122\n",
      "weighted avg       0.87      0.87      0.87       122\n",
      "\n",
      "Test Accuracy: 0.8689\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.85        51\n",
      "         1.0       0.90      0.87      0.89        71\n",
      "\n",
      "    accuracy                           0.87       122\n",
      "   macro avg       0.86      0.87      0.87       122\n",
      "weighted avg       0.87      0.87      0.87       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.8442622950819673, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8688524590163934]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Avg. Loss: 0.4666\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445, 8.755825779999494, 8.86405339521516, 8.971302146743026, 9.077608267949133, 9.183000923287103, 9.287507700817283, 9.391159644779835, 9.493978276292367, 9.595996403757146]\n",
      "Test Accuracy: 0.8689\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.85        51\n",
      "         1.0       0.90      0.87      0.89        71\n",
      "\n",
      "    accuracy                           0.87       122\n",
      "   macro avg       0.86      0.87      0.87       122\n",
      "weighted avg       0.87      0.87      0.87       122\n",
      "\n",
      "Test Accuracy: 0.8689\n",
      "Confusion Matrix:\n",
      "[[44  7]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.85        51\n",
      "         1.0       0.90      0.87      0.89        71\n",
      "\n",
      "    accuracy                           0.87       122\n",
      "   macro avg       0.86      0.87      0.87       122\n",
      "weighted avg       0.87      0.87      0.87       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.8442622950819673, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8688524590163934, 0.8688524590163934]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Avg. Loss: 0.5371\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445, 8.755825779999494, 8.86405339521516, 8.971302146743026, 9.077608267949133, 9.183000923287103, 9.287507700817283, 9.391159644779835, 9.493978276292367, 9.595996403757146, 9.697231536858443]\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81        51\n",
      "         1.0       0.86      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81        51\n",
      "         1.0       0.86      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.8442622950819673, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8688524590163934, 0.8688524590163934, 0.8442622950819673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Avg. Loss: 0.4198\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445, 8.755825779999494, 8.86405339521516, 8.971302146743026, 9.077608267949133, 9.183000923287103, 9.287507700817283, 9.391159644779835, 9.493978276292367, 9.595996403757146, 9.697231536858443, 9.797709264054285]\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81        51\n",
      "         1.0       0.86      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81        51\n",
      "         1.0       0.86      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.8442622950819673, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8688524590163934, 0.8688524590163934, 0.8442622950819673, 0.8442622950819673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Avg. Loss: 0.4303\n",
      "epsilon list is  [3.0192557293821984, 3.373513494746687, 3.6529455365628074, 3.898164140131536, 4.122318937338093, 4.3315876960907795, 4.529475714944004, 4.718213177909467, 4.899332210325066, 5.0739468116776685, 5.242900099813811, 5.406851366790849, 5.566330714600767, 5.721773563937807, 5.873542756941345, 6.021945505024222, 6.167247366775921, 6.309677434975158, 6.449435376211958, 6.586698593031849, 6.721625504426099, 6.854357455639281, 6.985018536663613, 7.113728166625174, 7.2405848082307545, 7.365686056737086, 7.489119867760549, 7.610964758919571, 7.731292769566628, 7.850174057707565, 7.9676718374684015, 8.083842541897697, 8.198741875002032, 8.312419096458132, 8.424926201096568, 8.536299535256731, 8.646585904643445, 8.755825779999494, 8.86405339521516, 8.971302146743026, 9.077608267949133, 9.183000923287103, 9.287507700817283, 9.391159644779835, 9.493978276292367, 9.595996403757146, 9.697231536858443, 9.797709264054285, 9.897446131522965]\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81        51\n",
      "         1.0       0.86      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Test Accuracy: 0.8443\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81        51\n",
      "         1.0       0.86      0.87      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.84      0.84      0.84       122\n",
      "weighted avg       0.84      0.84      0.84       122\n",
      "\n",
      "Accuracy list is  [0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6065573770491803, 0.7049180327868853, 0.7459016393442623, 0.8114754098360656, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.8852459016393442, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8524590163934426, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.8442622950819673, 0.860655737704918, 0.8524590163934426, 0.8524590163934426, 0.8442622950819673, 0.8442622950819673, 0.8524590163934426, 0.860655737704918, 0.8442622950819673, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8524590163934426, 0.8688524590163934, 0.8688524590163934, 0.8442622950819673, 0.8442622950819673, 0.8442622950819673]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from opacus import PrivacyEngine\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class HeartDiseaseModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(HeartDiseaseModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "input_size = 30  # number of features\n",
    "\n",
    "cleveland = pd.read_csv('C:/Users/siddh/heart_disease_data.csv')\n",
    "print('Shape of DataFrame: {}'.format(cleveland.shape))\n",
    "print(cleveland.loc[1])\n",
    "\n",
    "cleveland.head()\n",
    "\n",
    "data = cleveland[~cleveland.isin(['?'])]\n",
    "data.loc[280:]\n",
    "data = data.dropna(axis=0)\n",
    "\n",
    "# renaming columns\n",
    "data = data.rename(columns={'chest pain type': 'cps', 'resting bp s': 'rbps', 'fasting blood sugar': 'fbs',\n",
    "                            'resting ecg': 'recg', 'max heart rate': 'max_heart_rate', 'exercise angina': 'ex_angina',\n",
    "                            'ST slope': 'STslope'})\n",
    "\n",
    "# dealing with categorical variables for better inference with the model\n",
    "def convert_encoding(data):\n",
    "    dummies=pd.get_dummies(data['sex'],prefix='sex')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('sex',axis=1,inplace=True)\n",
    "\n",
    "    dummies=pd.get_dummies(data['slope'],prefix='slope')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('slope',axis=1,inplace=True)\n",
    "\n",
    "    dummies=pd.get_dummies(data['exang'],prefix='exang')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('exang',axis=1,inplace=True)\n",
    "\n",
    "    dummies=pd.get_dummies(data['restecg'],prefix='restecg')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('restecg',axis=1,inplace=True)\n",
    "\n",
    "    dummies=pd.get_dummies(data['cp'],prefix='cp')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('cp',axis=1,inplace=True)\n",
    "\n",
    "    dummies=pd.get_dummies(data['fbs'],prefix='fbs')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('fbs',axis=1,inplace=True)\n",
    "    \n",
    "    dummies=pd.get_dummies(data['ca'],prefix='ca')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('ca',axis=1,inplace=True)\n",
    "    \n",
    "    dummies=pd.get_dummies(data['thal'],prefix='thal')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('thal',axis=1,inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data=convert_encoding(data)\n",
    "\n",
    "y = data['target']\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = y.to_numpy()\n",
    "X = X.to_numpy()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=5)\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    return torch.from_numpy(df).float()\n",
    "\n",
    "X_traint = df_to_tensor(X_train)\n",
    "y_traint = df_to_tensor(y_train)\n",
    "X_testt = df_to_tensor(X_test)\n",
    "y_testt = df_to_tensor(y_test)\n",
    "\n",
    "train_ds = TensorDataset(X_traint, y_traint)\n",
    "test_ds = TensorDataset(X_testt, y_testt)\n",
    "\n",
    "# create data loaders\n",
    "batch_size = 5\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "delta=1e-7\n",
    "\n",
    "def train(model, train_dataloader, optimizer, epoch, epsilon_values):\n",
    "    \n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch, (data, target) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        target = target.unsqueeze(1).float()\n",
    "        target = target.repeat(1, output.shape[1])\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    epsilon = float(privacy_engine.get_epsilon(delta))\n",
    "    epsilon_values.append(epsilon)\n",
    "    print('Epoch: {}, Avg. Loss: {:.4f}'.format(epoch, np.mean(losses)))\n",
    "    return epsilon_values\n",
    "\n",
    "def test(model, test_dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            output = model(data)\n",
    "            predicted = torch.round(output)\n",
    "            predictions.extend(predicted.tolist())\n",
    "            targets.extend(target.tolist())\n",
    "    acc = accuracy_score(targets, predictions)\n",
    "    print('Test Accuracy: {:.4f}'.format(acc))\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(targets, predictions))\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(targets, predictions))\n",
    "    return acc\n",
    "\n",
    "colors = ['red', 'green', 'blue']\n",
    "x=[10,25,50]\n",
    "for i,j in enumerate(x):\n",
    "    accuracies = []\n",
    "    epsilon_list=[]\n",
    "    epsilon_values = []\n",
    "    epsilon_list_total=[]\n",
    "    model1 = HeartDiseaseModel(input_size)\n",
    "    model2 = HeartDiseaseModel(input_size)\n",
    "    model3 = HeartDiseaseModel(input_size)\n",
    "    if(i==0):\n",
    "        model=model1\n",
    "    elif (i==1):\n",
    "        model=model2\n",
    "    else:\n",
    "        model=model3\n",
    "        \n",
    "    privacy_engine = PrivacyEngine()\n",
    "    loss_fn = nn.BCELoss() # Binary Cross Entropy\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    model, optimizer, dataloader = privacy_engine.make_private_with_epsilon(module=model,optimizer=optimizer,data_loader=train_dataloader,\n",
    "                                                         max_grad_norm=1.0,target_epsilon=10, epochs=j, target_delta= 1e-7)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for epoch in range(1,j):\n",
    "        epsilon_list=train(model, train_dataloader, optimizer, epoch,epsilon_values)\n",
    "        print('epsilon list is ', epsilon_list)\n",
    "        test(model, test_dataloader)\n",
    "        acc = test(model, test_dataloader)\n",
    "        accuracies.append(acc)\n",
    "        print('Accuracy list is ',accuracies)\n",
    "    \n",
    "    if (i==0):\n",
    "        accuracies=[i*100 for i in accuracies]\n",
    "        plt.plot(epsilon_list, accuracies,color=\"red\",label='10 epochs')\n",
    "    elif(i==1):\n",
    "        accuracies=[i*100 for i in accuracies]\n",
    "        plt.plot(epsilon_list, accuracies,color=\"green\", label='25 epochs')\n",
    "    else:\n",
    "        accuracies=[i*100 for i in accuracies] \n",
    "        plt.plot(epsilon_list, accuracies, color=\"blue\", label='50 epochs')    \n",
    "    del model\n",
    "\n",
    "plt.xticks(range(0,10)) \n",
    "plt.yticks(range(int(accuracies[0]),100,3)) \n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Change in Accuracy with Epsilon')\n",
    "plt.legend(loc ='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# for x,y in zip(epsilon_list,accuracies):\n",
    "#     count = 0\n",
    "#     label = 'epoch'+ str(count)\n",
    "#     if(count%4==0):\n",
    "#         plt.annotate(label,(x,y),textcoords='offset points',xytext=(0,10),ha='center')\n",
    "#     else:\n",
    "#         continue\n",
    "#     count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e48a633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame: (606, 14)\n",
      "age          61.0\n",
      "sex           1.0\n",
      "cp            0.0\n",
      "trestbps    148.0\n",
      "chol        203.0\n",
      "fbs           0.0\n",
      "restecg       1.0\n",
      "thalach     161.0\n",
      "exang         0.0\n",
      "oldpeak       0.0\n",
      "slope         2.0\n",
      "ca            1.0\n",
      "thal          3.0\n",
      "target        0.0\n",
      "Name: 1, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Loss: 0.6922\n",
      "epsilon list is  [4.1502136976115525]\n",
      "Test Accuracy: 0.5902\n",
      "Confusion Matrix:\n",
      "[[ 1 50]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04        51\n",
      "         1.0       0.59      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.59       122\n",
      "   macro avg       0.79      0.51      0.39       122\n",
      "weighted avg       0.76      0.59      0.45       122\n",
      "\n",
      "Test Accuracy: 0.5902\n",
      "Confusion Matrix:\n",
      "[[ 1 50]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04        51\n",
      "         1.0       0.59      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.59       122\n",
      "   macro avg       0.79      0.51      0.39       122\n",
      "weighted avg       0.76      0.59      0.45       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Avg. Loss: 0.6911\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644]\n",
      "Test Accuracy: 0.5656\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 2 69]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.57      0.97      0.72        71\n",
      "\n",
      "    accuracy                           0.57       122\n",
      "   macro avg       0.29      0.49      0.36       122\n",
      "weighted avg       0.33      0.57      0.42       122\n",
      "\n",
      "Test Accuracy: 0.5656\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 2 69]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.57      0.97      0.72        71\n",
      "\n",
      "    accuracy                           0.57       122\n",
      "   macro avg       0.29      0.49      0.36       122\n",
      "weighted avg       0.33      0.57      0.42       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Avg. Loss: 0.6896\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Avg. Loss: 0.6866\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Avg. Loss: 0.6843\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Avg. Loss: 0.6791\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Avg. Loss: 0.6731\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777]\n",
      "Test Accuracy: 0.6230\n",
      "Confusion Matrix:\n",
      "[[ 5 46]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.10      0.18        51\n",
      "         1.0       0.61      1.00      0.76        71\n",
      "\n",
      "    accuracy                           0.62       122\n",
      "   macro avg       0.80      0.55      0.47       122\n",
      "weighted avg       0.77      0.62      0.51       122\n",
      "\n",
      "Test Accuracy: 0.6230\n",
      "Confusion Matrix:\n",
      "[[ 5 46]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.10      0.18        51\n",
      "         1.0       0.61      1.00      0.76        71\n",
      "\n",
      "    accuracy                           0.62       122\n",
      "   macro avg       0.80      0.55      0.47       122\n",
      "weighted avg       0.77      0.62      0.51       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Avg. Loss: 0.6631\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549]\n",
      "Test Accuracy: 0.6557\n",
      "Confusion Matrix:\n",
      "[[ 9 42]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.18      0.30        51\n",
      "         1.0       0.63      1.00      0.77        71\n",
      "\n",
      "    accuracy                           0.66       122\n",
      "   macro avg       0.81      0.59      0.54       122\n",
      "weighted avg       0.78      0.66      0.57       122\n",
      "\n",
      "Test Accuracy: 0.6557\n",
      "Confusion Matrix:\n",
      "[[ 9 42]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.18      0.30        51\n",
      "         1.0       0.63      1.00      0.77        71\n",
      "\n",
      "    accuracy                           0.66       122\n",
      "   macro avg       0.81      0.59      0.54       122\n",
      "weighted avg       0.78      0.66      0.57       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Avg. Loss: 0.6476\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887]\n",
      "Test Accuracy: 0.6885\n",
      "Confusion Matrix:\n",
      "[[13 38]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.25      0.41        51\n",
      "         1.0       0.65      1.00      0.79        71\n",
      "\n",
      "    accuracy                           0.69       122\n",
      "   macro avg       0.83      0.63      0.60       122\n",
      "weighted avg       0.80      0.69      0.63       122\n",
      "\n",
      "Test Accuracy: 0.6885\n",
      "Confusion Matrix:\n",
      "[[13 38]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.25      0.41        51\n",
      "         1.0       0.65      1.00      0.79        71\n",
      "\n",
      "    accuracy                           0.69       122\n",
      "   macro avg       0.83      0.63      0.60       122\n",
      "weighted avg       0.80      0.69      0.63       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Avg. Loss: 0.6303\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928]\n",
      "Test Accuracy: 0.7213\n",
      "Confusion Matrix:\n",
      "[[17 34]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.33      0.50        51\n",
      "         1.0       0.68      1.00      0.81        71\n",
      "\n",
      "    accuracy                           0.72       122\n",
      "   macro avg       0.84      0.67      0.65       122\n",
      "weighted avg       0.81      0.72      0.68       122\n",
      "\n",
      "Test Accuracy: 0.7213\n",
      "Confusion Matrix:\n",
      "[[17 34]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.33      0.50        51\n",
      "         1.0       0.68      1.00      0.81        71\n",
      "\n",
      "    accuracy                           0.72       122\n",
      "   macro avg       0.84      0.67      0.65       122\n",
      "weighted avg       0.81      0.72      0.68       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Avg. Loss: 0.6085\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846]\n",
      "Test Accuracy: 0.7623\n",
      "Confusion Matrix:\n",
      "[[23 28]\n",
      " [ 1 70]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.45      0.61        51\n",
      "         1.0       0.71      0.99      0.83        71\n",
      "\n",
      "    accuracy                           0.76       122\n",
      "   macro avg       0.84      0.72      0.72       122\n",
      "weighted avg       0.82      0.76      0.74       122\n",
      "\n",
      "Test Accuracy: 0.7623\n",
      "Confusion Matrix:\n",
      "[[23 28]\n",
      " [ 1 70]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.45      0.61        51\n",
      "         1.0       0.71      0.99      0.83        71\n",
      "\n",
      "    accuracy                           0.76       122\n",
      "   macro avg       0.84      0.72      0.72       122\n",
      "weighted avg       0.82      0.76      0.74       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Avg. Loss: 0.5686\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263]\n",
      "Test Accuracy: 0.8361\n",
      "Confusion Matrix:\n",
      "[[34 17]\n",
      " [ 3 68]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.67      0.77        51\n",
      "         1.0       0.80      0.96      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.86      0.81      0.82       122\n",
      "weighted avg       0.85      0.84      0.83       122\n",
      "\n",
      "Test Accuracy: 0.8361\n",
      "Confusion Matrix:\n",
      "[[34 17]\n",
      " [ 3 68]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.67      0.77        51\n",
      "         1.0       0.80      0.96      0.87        71\n",
      "\n",
      "    accuracy                           0.84       122\n",
      "   macro avg       0.86      0.81      0.82       122\n",
      "weighted avg       0.85      0.84      0.83       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Avg. Loss: 0.5310\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048]\n",
      "Test Accuracy: 0.8279\n",
      "Confusion Matrix:\n",
      "[[34 17]\n",
      " [ 4 67]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.67      0.76        51\n",
      "         1.0       0.80      0.94      0.86        71\n",
      "\n",
      "    accuracy                           0.83       122\n",
      "   macro avg       0.85      0.81      0.81       122\n",
      "weighted avg       0.84      0.83      0.82       122\n",
      "\n",
      "Test Accuracy: 0.8279\n",
      "Confusion Matrix:\n",
      "[[34 17]\n",
      " [ 4 67]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.67      0.76        51\n",
      "         1.0       0.80      0.94      0.86        71\n",
      "\n",
      "    accuracy                           0.83       122\n",
      "   macro avg       0.85      0.81      0.81       122\n",
      "weighted avg       0.84      0.83      0.82       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918, 0.8278688524590164]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Avg. Loss: 0.4887\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[38 13]\n",
      " [ 4 67]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.75      0.82        51\n",
      "         1.0       0.84      0.94      0.89        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.87      0.84      0.85       122\n",
      "weighted avg       0.87      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[38 13]\n",
      " [ 4 67]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.75      0.82        51\n",
      "         1.0       0.84      0.94      0.89        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.87      0.84      0.85       122\n",
      "weighted avg       0.87      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918, 0.8278688524590164, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Avg. Loss: 0.4343\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[38 13]\n",
      " [ 4 67]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.75      0.82        51\n",
      "         1.0       0.84      0.94      0.89        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.87      0.84      0.85       122\n",
      "weighted avg       0.87      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[38 13]\n",
      " [ 4 67]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.75      0.82        51\n",
      "         1.0       0.84      0.94      0.89        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.87      0.84      0.85       122\n",
      "weighted avg       0.87      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918, 0.8278688524590164, 0.860655737704918, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Avg. Loss: 0.4142\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016]\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[38 13]\n",
      " [ 5 66]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.75      0.81        51\n",
      "         1.0       0.84      0.93      0.88        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.86      0.84      0.84       122\n",
      "weighted avg       0.86      0.85      0.85       122\n",
      "\n",
      "Test Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[38 13]\n",
      " [ 5 66]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.75      0.81        51\n",
      "         1.0       0.84      0.93      0.88        71\n",
      "\n",
      "    accuracy                           0.85       122\n",
      "   macro avg       0.86      0.84      0.84       122\n",
      "weighted avg       0.86      0.85      0.85       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918, 0.8278688524590164, 0.860655737704918, 0.860655737704918, 0.8524590163934426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Avg. Loss: 0.4054\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161]\n",
      "Test Accuracy: 0.8689\n",
      "Confusion Matrix:\n",
      "[[40 11]\n",
      " [ 5 66]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.78      0.83        51\n",
      "         1.0       0.86      0.93      0.89        71\n",
      "\n",
      "    accuracy                           0.87       122\n",
      "   macro avg       0.87      0.86      0.86       122\n",
      "weighted avg       0.87      0.87      0.87       122\n",
      "\n",
      "Test Accuracy: 0.8689\n",
      "Confusion Matrix:\n",
      "[[40 11]\n",
      " [ 5 66]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.78      0.83        51\n",
      "         1.0       0.86      0.93      0.89        71\n",
      "\n",
      "    accuracy                           0.87       122\n",
      "   macro avg       0.87      0.86      0.86       122\n",
      "weighted avg       0.87      0.87      0.87       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918, 0.8278688524590164, 0.860655737704918, 0.860655737704918, 0.8524590163934426, 0.8688524590163934]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Avg. Loss: 0.4084\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[40 11]\n",
      " [ 6 65]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.78      0.82        51\n",
      "         1.0       0.86      0.92      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.85       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[40 11]\n",
      " [ 6 65]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.78      0.82        51\n",
      "         1.0       0.86      0.92      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.85       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918, 0.8278688524590164, 0.860655737704918, 0.860655737704918, 0.8524590163934426, 0.8688524590163934, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Avg. Loss: 0.3768\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616]\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85        51\n",
      "         1.0       0.89      0.90      0.90        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.87      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85        51\n",
      "         1.0       0.89      0.90      0.90        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.87      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918, 0.8278688524590164, 0.860655737704918, 0.860655737704918, 0.8524590163934426, 0.8688524590163934, 0.860655737704918, 0.8770491803278688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Avg. Loss: 0.3799\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272]\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85        51\n",
      "         1.0       0.89      0.90      0.90        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.87      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85        51\n",
      "         1.0       0.89      0.90      0.90        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.87      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918, 0.8278688524590164, 0.860655737704918, 0.860655737704918, 0.8524590163934426, 0.8688524590163934, 0.860655737704918, 0.8770491803278688, 0.8770491803278688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Avg. Loss: 0.3677\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272, 9.299034730630312]\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85        51\n",
      "         1.0       0.89      0.90      0.90        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.87      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85        51\n",
      "         1.0       0.89      0.90      0.90        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.87      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918, 0.8278688524590164, 0.860655737704918, 0.860655737704918, 0.8524590163934426, 0.8688524590163934, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Avg. Loss: 0.4202\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272, 9.299034730630312, 9.47798056108359]\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85        51\n",
      "         1.0       0.89      0.90      0.90        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.87      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Test Accuracy: 0.8770\n",
      "Confusion Matrix:\n",
      "[[43  8]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85        51\n",
      "         1.0       0.89      0.90      0.90        71\n",
      "\n",
      "    accuracy                           0.88       122\n",
      "   macro avg       0.87      0.87      0.87       122\n",
      "weighted avg       0.88      0.88      0.88       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918, 0.8278688524590164, 0.860655737704918, 0.860655737704918, 0.8524590163934426, 0.8688524590163934, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Avg. Loss: 0.3861\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272, 9.299034730630312, 9.47798056108359, 9.654073569144057]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918, 0.8278688524590164, 0.860655737704918, 0.860655737704918, 0.8524590163934426, 0.8688524590163934, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Avg. Loss: 0.4076\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272, 9.299034730630312, 9.47798056108359, 9.654073569144057, 9.82748481670542]\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Test Accuracy: 0.8607\n",
      "Confusion Matrix:\n",
      "[[41 10]\n",
      " [ 7 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83        51\n",
      "         1.0       0.86      0.90      0.88        71\n",
      "\n",
      "    accuracy                           0.86       122\n",
      "   macro avg       0.86      0.85      0.86       122\n",
      "weighted avg       0.86      0.86      0.86       122\n",
      "\n",
      "Accuracy list is  [0.5901639344262295, 0.5655737704918032, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.6229508196721312, 0.6557377049180327, 0.6885245901639344, 0.7213114754098361, 0.7622950819672131, 0.8360655737704918, 0.8278688524590164, 0.860655737704918, 0.860655737704918, 0.8524590163934426, 0.8688524590163934, 0.860655737704918, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.8770491803278688, 0.860655737704918, 0.860655737704918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Loss: 0.6966\n",
      "epsilon list is  [4.1502136976115525]\n",
      "Test Accuracy: 0.4180\n",
      "Confusion Matrix:\n",
      "[[51  0]\n",
      " [71  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.59        51\n",
      "         1.0       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.42       122\n",
      "   macro avg       0.21      0.50      0.29       122\n",
      "weighted avg       0.17      0.42      0.25       122\n",
      "\n",
      "Test Accuracy: 0.4180\n",
      "Confusion Matrix:\n",
      "[[51  0]\n",
      " [71  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.59        51\n",
      "         1.0       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.42       122\n",
      "   macro avg       0.21      0.50      0.29       122\n",
      "weighted avg       0.17      0.42      0.25       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Avg. Loss: 0.6932\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644]\n",
      "Test Accuracy: 0.4180\n",
      "Confusion Matrix:\n",
      "[[51  0]\n",
      " [71  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.59        51\n",
      "         1.0       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.42       122\n",
      "   macro avg       0.21      0.50      0.29       122\n",
      "weighted avg       0.17      0.42      0.25       122\n",
      "\n",
      "Test Accuracy: 0.4180\n",
      "Confusion Matrix:\n",
      "[[51  0]\n",
      " [71  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.59        51\n",
      "         1.0       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.42       122\n",
      "   macro avg       0.21      0.50      0.29       122\n",
      "weighted avg       0.17      0.42      0.25       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Avg. Loss: 0.6932\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645]\n",
      "Test Accuracy: 0.4344\n",
      "Confusion Matrix:\n",
      "[[51  0]\n",
      " [69  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.60        51\n",
      "         1.0       1.00      0.03      0.05        71\n",
      "\n",
      "    accuracy                           0.43       122\n",
      "   macro avg       0.71      0.51      0.33       122\n",
      "weighted avg       0.76      0.43      0.28       122\n",
      "\n",
      "Test Accuracy: 0.4344\n",
      "Confusion Matrix:\n",
      "[[51  0]\n",
      " [69  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.60        51\n",
      "         1.0       1.00      0.03      0.05        71\n",
      "\n",
      "    accuracy                           0.43       122\n",
      "   macro avg       0.71      0.51      0.33       122\n",
      "weighted avg       0.76      0.43      0.28       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Avg. Loss: 0.6910\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726]\n",
      "Test Accuracy: 0.5082\n",
      "Confusion Matrix:\n",
      "[[49  2]\n",
      " [58 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.96      0.62        51\n",
      "         1.0       0.87      0.18      0.30        71\n",
      "\n",
      "    accuracy                           0.51       122\n",
      "   macro avg       0.66      0.57      0.46       122\n",
      "weighted avg       0.70      0.51      0.44       122\n",
      "\n",
      "Test Accuracy: 0.5082\n",
      "Confusion Matrix:\n",
      "[[49  2]\n",
      " [58 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.96      0.62        51\n",
      "         1.0       0.87      0.18      0.30        71\n",
      "\n",
      "    accuracy                           0.51       122\n",
      "   macro avg       0.66      0.57      0.46       122\n",
      "weighted avg       0.70      0.51      0.44       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Avg. Loss: 0.6935\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134]\n",
      "Test Accuracy: 0.5164\n",
      "Confusion Matrix:\n",
      "[[47  4]\n",
      " [55 16]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.92      0.61        51\n",
      "         1.0       0.80      0.23      0.35        71\n",
      "\n",
      "    accuracy                           0.52       122\n",
      "   macro avg       0.63      0.57      0.48       122\n",
      "weighted avg       0.66      0.52      0.46       122\n",
      "\n",
      "Test Accuracy: 0.5164\n",
      "Confusion Matrix:\n",
      "[[47  4]\n",
      " [55 16]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.92      0.61        51\n",
      "         1.0       0.80      0.23      0.35        71\n",
      "\n",
      "    accuracy                           0.52       122\n",
      "   macro avg       0.63      0.57      0.48       122\n",
      "weighted avg       0.66      0.52      0.46       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Avg. Loss: 0.6922\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677]\n",
      "Test Accuracy: 0.6393\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [35 36]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.82      0.66        51\n",
      "         1.0       0.80      0.51      0.62        71\n",
      "\n",
      "    accuracy                           0.64       122\n",
      "   macro avg       0.67      0.67      0.64       122\n",
      "weighted avg       0.69      0.64      0.64       122\n",
      "\n",
      "Test Accuracy: 0.6393\n",
      "Confusion Matrix:\n",
      "[[42  9]\n",
      " [35 36]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.82      0.66        51\n",
      "         1.0       0.80      0.51      0.62        71\n",
      "\n",
      "    accuracy                           0.64       122\n",
      "   macro avg       0.67      0.67      0.64       122\n",
      "weighted avg       0.69      0.64      0.64       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Avg. Loss: 0.6922\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777]\n",
      "Test Accuracy: 0.7131\n",
      "Confusion Matrix:\n",
      "[[37 14]\n",
      " [21 50]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.73      0.68        51\n",
      "         1.0       0.78      0.70      0.74        71\n",
      "\n",
      "    accuracy                           0.71       122\n",
      "   macro avg       0.71      0.71      0.71       122\n",
      "weighted avg       0.72      0.71      0.71       122\n",
      "\n",
      "Test Accuracy: 0.7131\n",
      "Confusion Matrix:\n",
      "[[37 14]\n",
      " [21 50]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.73      0.68        51\n",
      "         1.0       0.78      0.70      0.74        71\n",
      "\n",
      "    accuracy                           0.71       122\n",
      "   macro avg       0.71      0.71      0.71       122\n",
      "weighted avg       0.72      0.71      0.71       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Avg. Loss: 0.6898\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549]\n",
      "Test Accuracy: 0.7705\n",
      "Confusion Matrix:\n",
      "[[32 19]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.63      0.70        51\n",
      "         1.0       0.77      0.87      0.82        71\n",
      "\n",
      "    accuracy                           0.77       122\n",
      "   macro avg       0.77      0.75      0.76       122\n",
      "weighted avg       0.77      0.77      0.77       122\n",
      "\n",
      "Test Accuracy: 0.7705\n",
      "Confusion Matrix:\n",
      "[[32 19]\n",
      " [ 9 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.63      0.70        51\n",
      "         1.0       0.77      0.87      0.82        71\n",
      "\n",
      "    accuracy                           0.77       122\n",
      "   macro avg       0.77      0.75      0.76       122\n",
      "weighted avg       0.77      0.77      0.77       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Avg. Loss: 0.6888\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887]\n",
      "Test Accuracy: 0.7541\n",
      "Confusion Matrix:\n",
      "[[22 29]\n",
      " [ 1 70]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.43      0.59        51\n",
      "         1.0       0.71      0.99      0.82        71\n",
      "\n",
      "    accuracy                           0.75       122\n",
      "   macro avg       0.83      0.71      0.71       122\n",
      "weighted avg       0.81      0.75      0.73       122\n",
      "\n",
      "Test Accuracy: 0.7541\n",
      "Confusion Matrix:\n",
      "[[22 29]\n",
      " [ 1 70]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.43      0.59        51\n",
      "         1.0       0.71      0.99      0.82        71\n",
      "\n",
      "    accuracy                           0.75       122\n",
      "   macro avg       0.83      0.71      0.71       122\n",
      "weighted avg       0.81      0.75      0.73       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Avg. Loss: 0.6893\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928]\n",
      "Test Accuracy: 0.6311\n",
      "Confusion Matrix:\n",
      "[[ 6 45]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.12      0.21        51\n",
      "         1.0       0.61      1.00      0.76        71\n",
      "\n",
      "    accuracy                           0.63       122\n",
      "   macro avg       0.81      0.56      0.48       122\n",
      "weighted avg       0.77      0.63      0.53       122\n",
      "\n",
      "Test Accuracy: 0.6311\n",
      "Confusion Matrix:\n",
      "[[ 6 45]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.12      0.21        51\n",
      "         1.0       0.61      1.00      0.76        71\n",
      "\n",
      "    accuracy                           0.63       122\n",
      "   macro avg       0.81      0.56      0.48       122\n",
      "weighted avg       0.77      0.63      0.53       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Avg. Loss: 0.6874\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846]\n",
      "Test Accuracy: 0.6230\n",
      "Confusion Matrix:\n",
      "[[ 5 46]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.10      0.18        51\n",
      "         1.0       0.61      1.00      0.76        71\n",
      "\n",
      "    accuracy                           0.62       122\n",
      "   macro avg       0.80      0.55      0.47       122\n",
      "weighted avg       0.77      0.62      0.51       122\n",
      "\n",
      "Test Accuracy: 0.6230\n",
      "Confusion Matrix:\n",
      "[[ 5 46]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.10      0.18        51\n",
      "         1.0       0.61      1.00      0.76        71\n",
      "\n",
      "    accuracy                           0.62       122\n",
      "   macro avg       0.80      0.55      0.47       122\n",
      "weighted avg       0.77      0.62      0.51       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Avg. Loss: 0.6863\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263]\n",
      "Test Accuracy: 0.6148\n",
      "Confusion Matrix:\n",
      "[[ 4 47]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.08      0.15        51\n",
      "         1.0       0.60      1.00      0.75        71\n",
      "\n",
      "    accuracy                           0.61       122\n",
      "   macro avg       0.80      0.54      0.45       122\n",
      "weighted avg       0.77      0.61      0.50       122\n",
      "\n",
      "Test Accuracy: 0.6148\n",
      "Confusion Matrix:\n",
      "[[ 4 47]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.08      0.15        51\n",
      "         1.0       0.60      1.00      0.75        71\n",
      "\n",
      "    accuracy                           0.61       122\n",
      "   macro avg       0.80      0.54      0.45       122\n",
      "weighted avg       0.77      0.61      0.50       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Avg. Loss: 0.6856\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048]\n",
      "Test Accuracy: 0.5902\n",
      "Confusion Matrix:\n",
      "[[ 1 50]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04        51\n",
      "         1.0       0.59      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.59       122\n",
      "   macro avg       0.79      0.51      0.39       122\n",
      "weighted avg       0.76      0.59      0.45       122\n",
      "\n",
      "Test Accuracy: 0.5902\n",
      "Confusion Matrix:\n",
      "[[ 1 50]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04        51\n",
      "         1.0       0.59      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.59       122\n",
      "   macro avg       0.79      0.51      0.39       122\n",
      "weighted avg       0.76      0.59      0.45       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558, 0.5901639344262295]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Avg. Loss: 0.6858\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887]\n",
      "Test Accuracy: 0.5902\n",
      "Confusion Matrix:\n",
      "[[ 1 50]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04        51\n",
      "         1.0       0.59      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.59       122\n",
      "   macro avg       0.79      0.51      0.39       122\n",
      "weighted avg       0.76      0.59      0.45       122\n",
      "\n",
      "Test Accuracy: 0.5902\n",
      "Confusion Matrix:\n",
      "[[ 1 50]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04        51\n",
      "         1.0       0.59      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.59       122\n",
      "   macro avg       0.79      0.51      0.39       122\n",
      "weighted avg       0.76      0.59      0.45       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558, 0.5901639344262295, 0.5901639344262295]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Avg. Loss: 0.6855\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287]\n",
      "Test Accuracy: 0.5902\n",
      "Confusion Matrix:\n",
      "[[ 1 50]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04        51\n",
      "         1.0       0.59      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.59       122\n",
      "   macro avg       0.79      0.51      0.39       122\n",
      "weighted avg       0.76      0.59      0.45       122\n",
      "\n",
      "Test Accuracy: 0.5902\n",
      "Confusion Matrix:\n",
      "[[ 1 50]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04        51\n",
      "         1.0       0.59      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.59       122\n",
      "   macro avg       0.79      0.51      0.39       122\n",
      "weighted avg       0.76      0.59      0.45       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558, 0.5901639344262295, 0.5901639344262295, 0.5901639344262295]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Avg. Loss: 0.6841\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558, 0.5901639344262295, 0.5901639344262295, 0.5901639344262295, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Avg. Loss: 0.6832\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558, 0.5901639344262295, 0.5901639344262295, 0.5901639344262295, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Avg. Loss: 0.6825\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558, 0.5901639344262295, 0.5901639344262295, 0.5901639344262295, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Avg. Loss: 0.6832\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558, 0.5901639344262295, 0.5901639344262295, 0.5901639344262295, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Avg. Loss: 0.6817\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558, 0.5901639344262295, 0.5901639344262295, 0.5901639344262295, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Avg. Loss: 0.6793\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272, 9.299034730630312]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558, 0.5901639344262295, 0.5901639344262295, 0.5901639344262295, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Avg. Loss: 0.6792\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272, 9.299034730630312, 9.47798056108359]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558, 0.5901639344262295, 0.5901639344262295, 0.5901639344262295, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Avg. Loss: 0.6784\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272, 9.299034730630312, 9.47798056108359, 9.654073569144057]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558, 0.5901639344262295, 0.5901639344262295, 0.5901639344262295, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Avg. Loss: 0.6762\n",
      "epsilon list is  [4.1502136976115525, 4.662004808994644, 5.0678346543264645, 5.420550485068726, 5.739465600235134, 6.034345909942677, 6.310954601472777, 6.573030411284549, 6.823161631196887, 7.063227993069928, 7.294648270357846, 7.518527947124263, 7.735741993207048, 7.947007118516887, 8.152911985553287, 8.353950540250016, 8.550546704115161, 8.743059553849188, 8.931800996203616, 9.117046199938272, 9.299034730630312, 9.47798056108359, 9.654073569144057, 9.82748481670542]\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Test Accuracy: 0.5820\n",
      "Confusion Matrix:\n",
      "[[ 0 51]\n",
      " [ 0 71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.58      1.00      0.74        71\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.29      0.50      0.37       122\n",
      "weighted avg       0.34      0.58      0.43       122\n",
      "\n",
      "Accuracy list is  [0.4180327868852459, 0.4180327868852459, 0.4344262295081967, 0.5081967213114754, 0.5163934426229508, 0.639344262295082, 0.7131147540983607, 0.7704918032786885, 0.7540983606557377, 0.6311475409836066, 0.6229508196721312, 0.6147540983606558, 0.5901639344262295, 0.5901639344262295, 0.5901639344262295, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541, 0.5819672131147541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\siddh\\anaconda3\\envs\\gpu2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from opacus import PrivacyEngine\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class HeartDiseaseModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(HeartDiseaseModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "input_size = 30  # number of features\n",
    "\n",
    "cleveland = pd.read_csv('C:/Users/siddh/heart_disease_data.csv')\n",
    "print('Shape of DataFrame: {}'.format(cleveland.shape))\n",
    "print(cleveland.loc[1])\n",
    "cleveland.head()\n",
    "data = cleveland[~cleveland.isin(['?'])]\n",
    "data.loc[280:]\n",
    "data = data.dropna(axis=0)\n",
    "\n",
    "# renaming columns\n",
    "data = data.rename(columns={'chest pain type': 'cps', 'resting bp s': 'rbps', 'fasting blood sugar': 'fbs',\n",
    "                            'resting ecg': 'recg', 'max heart rate': 'max_heart_rate', 'exercise angina': 'ex_angina',\n",
    "                            'ST slope': 'STslope'})\n",
    "\n",
    "# dealing with categorical variables for better inference with the model\n",
    "def convert_encoding(data):\n",
    "    dummies=pd.get_dummies(data['sex'],prefix='sex')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('sex',axis=1,inplace=True)\n",
    "\n",
    "    dummies=pd.get_dummies(data['slope'],prefix='slope')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('slope',axis=1,inplace=True)\n",
    "\n",
    "    dummies=pd.get_dummies(data['exang'],prefix='exang')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('exang',axis=1,inplace=True)\n",
    "\n",
    "    dummies=pd.get_dummies(data['restecg'],prefix='restecg')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('restecg',axis=1,inplace=True)\n",
    "\n",
    "    dummies=pd.get_dummies(data['cp'],prefix='cp')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('cp',axis=1,inplace=True)\n",
    "\n",
    "    dummies=pd.get_dummies(data['fbs'],prefix='fbs')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('fbs',axis=1,inplace=True)\n",
    "    \n",
    "    dummies=pd.get_dummies(data['ca'],prefix='ca')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('ca',axis=1,inplace=True)\n",
    "    \n",
    "    dummies=pd.get_dummies(data['thal'],prefix='thal')\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop('thal',axis=1,inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data=convert_encoding(data)\n",
    "\n",
    "y = data['target']\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = y.to_numpy()\n",
    "X = X.to_numpy()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=5)\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    return torch.from_numpy(df).float()\n",
    "\n",
    "X_traint = df_to_tensor(X_train)\n",
    "y_traint = df_to_tensor(y_train)\n",
    "X_testt = df_to_tensor(X_test)\n",
    "y_testt = df_to_tensor(y_test)\n",
    "train_ds = TensorDataset(X_traint, y_traint)\n",
    "test_ds = TensorDataset(X_testt, y_testt)\n",
    "\n",
    "# create data loaders\n",
    "batch_size = 5\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "delta=1e-7\n",
    "\n",
    "def train(model, train_dataloader, optimizer, epoch, epsilon_values):\n",
    "    \n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch, (data, target) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        target = target.unsqueeze(1).float()\n",
    "        target = target.repeat(1, output.shape[1])\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    epsilon = float(privacy_engine.get_epsilon(delta))\n",
    "    epsilon_values.append(epsilon)\n",
    "    print('Epoch: {}, Avg. Loss: {:.4f}'.format(epoch, np.mean(losses)))\n",
    "    return epsilon_values\n",
    "\n",
    "def test(model, test_dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            output = model(data)\n",
    "            predicted = torch.round(output)\n",
    "            predictions.extend(predicted.tolist())\n",
    "            targets.extend(target.tolist())\n",
    "    acc = accuracy_score(targets, predictions)\n",
    "    print('Test Accuracy: {:.4f}'.format(acc))\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(targets, predictions))\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(targets, predictions))\n",
    "    return acc\n",
    "\n",
    "colors = ['red', 'green', 'blue']\n",
    "x=[\"adam\",\"SGD\"]\n",
    "for i,j in enumerate(x):\n",
    "    accuracies = []\n",
    "    epsilon_list=[]\n",
    "    epsilon_values = []\n",
    "    epsilon_list_total=[]\n",
    "    model1 = HeartDiseaseModel(input_size)\n",
    "    model2 = HeartDiseaseModel(input_size)\n",
    "    if(i==0):\n",
    "        model=model1\n",
    "    elif (i==1):\n",
    "        model=model2\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    loss_fn = nn.BCELoss() # Binary Cross Entropy\n",
    "    if(j==\"adam\"):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "    model, optimizer, dataloader = privacy_engine.make_private_with_epsilon(module=model,optimizer=optimizer,data_loader=train_dataloader,\n",
    "                                                         max_grad_norm=1.0,target_epsilon=10, epochs=25, target_delta= 1e-7)\n",
    "    criterion = nn.BCELoss()\n",
    "    for epoch in range(1,25):\n",
    "        epsilon_list=train(model, train_dataloader, optimizer, epoch,epsilon_values)\n",
    "        print('epsilon list is ', epsilon_list)\n",
    "        test(model, test_dataloader)\n",
    "        acc = test(model, test_dataloader)\n",
    "        accuracies.append(acc)\n",
    "        print('Accuracy list is ',accuracies)\n",
    "    \n",
    "    if (i==0):\n",
    "        accuracies=[i*100 for i in accuracies]\n",
    "        plt.plot(epsilon_list, accuracies,color=\"red\",label='ADAM optimizer')\n",
    "    elif(i==1):\n",
    "        accuracies=[i*100 for i in accuracies]\n",
    "        plt.plot(epsilon_list, accuracies,color=\"green\", label='SGD optimizer',linestyle='dashed')  \n",
    "    del model\n",
    "\n",
    "plt.xticks(range(0,10)) \n",
    "plt.yticks(range(int(accuracies[0]),100,3)) \n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Change in Accuracy with Epsilon')\n",
    "plt.legend(loc ='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# for x,y in zip(epsilon_list,accuracies):\n",
    "#     count = 0\n",
    "#     label = 'epoch'+ str(count)\n",
    "#     if(count%4==0):\n",
    "#         plt.annotate(label,(x,y),textcoords='offset points',xytext=(0,10),ha='center')\n",
    "#     else:\n",
    "#         continue\n",
    "#     count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77233d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80128c-d104-457e-a4ec-c25b062eb4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
